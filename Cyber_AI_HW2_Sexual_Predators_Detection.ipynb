{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/bergeramit/SexualPredatorDetection/blob/main/Cyber_AI_HW2_Sexual_Predators_Detection.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Op83Dr1lNWUI"
      },
      "source": [
        "# Assignment 2 - Sexual Predators Detection"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xjsjna-mIszN"
      },
      "source": [
        "# Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jkcqohEtl3nw",
        "outputId": "7d7fdc96-685b-4f97-d24e-f0c1e6ea4162"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting transformers\n",
            "  Downloading transformers-4.20.1-py3-none-any.whl (4.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 4.4 MB 5.0 MB/s \n",
            "\u001b[?25hCollecting tokenizers!=0.11.3,<0.13,>=0.11.1\n",
            "  Downloading tokenizers-0.12.1-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (6.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 6.6 MB 27.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.7.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.6)\n",
            "Collecting huggingface-hub<1.0,>=0.1.0\n",
            "  Downloading huggingface_hub-0.8.1-py3-none-any.whl (101 kB)\n",
            "\u001b[K     |████████████████████████████████| 101 kB 8.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2022.6.2)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.11.4)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.64.0)\n",
            "Collecting pyyaml>=5.1\n",
            "  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n",
            "\u001b[K     |████████████████████████████████| 596 kB 49.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (4.1.1)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.9)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.8.0)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2022.6.15)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Installing collected packages: pyyaml, tokenizers, huggingface-hub, transformers\n",
            "  Attempting uninstall: pyyaml\n",
            "    Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "Successfully installed huggingface-hub-0.8.1 pyyaml-6.0 tokenizers-0.12.1 transformers-4.20.1\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install bitstring"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C17Sttx6MFx0",
        "outputId": "18275894-fdeb-46ae-b108-fcd1b47cb899"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting bitstring\n",
            "  Downloading bitstring-3.1.9-py3-none-any.whl (38 kB)\n",
            "Installing collected packages: bitstring\n",
            "Successfully installed bitstring-3.1.9\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oq8WMy8blzdw"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from sklearn.metrics import classification_report\n",
        "from transformers import BertTokenizer, BertForSequenceClassification, AutoConfig, AutoModel\n",
        "from tqdm import tqdm\n",
        "import nltk\n",
        "import os\n",
        "import string\n",
        "import xml.etree.ElementTree as ET\n",
        "import pandas as pd\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from xml.sax.saxutils import escape, unescape\n",
        "# !pip install openai"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YT3RCAmjmAnL",
        "outputId": "9dbcddc1-03e7-48f2-959e-42a3722c13c8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KRuiyzaTnBHO",
        "outputId": "89f51850-ca1b-486b-b089-0e58601c9090"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "'drive/MyDrive/MSc/CyberAI/Miniproject/All English Stopwords (700+)/stopwords_All_English_Stopwords_700.txt'\n"
          ]
        }
      ],
      "source": [
        "!ls drive/MyDrive/MSc/CyberAI/Miniproject/'All English Stopwords (700+)'/stopwords_All_English_Stopwords_700.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U6Jo8fFfl5R0"
      },
      "outputs": [],
      "source": [
        "# Settings\n",
        "device = torch.device(\"cuda\")\n",
        "NUM_EPOCHS = 1\n",
        "DRIVE_PREFIX = \"drive/MyDrive/MSc/CyberAI/Miniproject/\"\n",
        "\n",
        "# ------------- <pan12 dataset> ------------- #\n",
        "PAN12_DATASET = os.path.join(DRIVE_PREFIX, \"pan12-sexual-predator-identification-test-and-training\")\n",
        "\n",
        "PAN12_TRAINING_DIRECTORY = os.path.join(PAN12_DATASET, \"pan12-sexual-predator-identification-training-corpus-2012-05-01\")\n",
        "PAN12_TRAINING_DIFF = os.path.join(PAN12_TRAINING_DIRECTORY, \"pan12-sexual-predator-identification-diff.txt\")\n",
        "PAN12_TRAINING_CHATS = os.path.join(PAN12_TRAINING_DIRECTORY, \"pan12-sexual-predator-identification-training-corpus-2012-05-01.xml\")\n",
        "PAN12_TRAINING_PREDATORS = os.path.join(PAN12_TRAINING_DIRECTORY, \"pan12-sexual-predator-identification-training-corpus-predators-2012-05-01.txt\")\n",
        "\n",
        "PAN12_TEST_DIRECTORY = os.path.join(PAN12_DATASET, \"pan12-sexual-predator-identification-test-corpus-2012-05-21\")\n",
        "PAN12_TEST_PREDATORS = os.path.join(PAN12_TEST_DIRECTORY, \"pan12-sexual-predator-identification-groundtruth-problem1.txt\")\n",
        "PAN12_TEST_CHATS = os.path.join(PAN12_TEST_DIRECTORY, \"pan12-sexual-predator-identification-test-corpus-2012-05-17.xml\")\n",
        "PAN12_TEST_HARRASSMENT_LINES = os.path.join(PAN12_TEST_DIRECTORY, \"pan12-sexual-predator-identification-groundtruth-problem2.txt\")\n",
        "\n",
        "# ------------- </pan12 dataset> ------------- #\n",
        "\n",
        "# ------------- <Chat Slang Abbreviations Acronyms dataset> ------------- #\n",
        "CHAT_SLANG_ABBREVIATIONS_DIRECTORY = os.path.join(DRIVE_PREFIX, \"Chat Internet Slang Abbreviations Acronyms\")\n",
        "CHAT_SLANG_ABBREVIATIONS_DATASET = os.path.join(CHAT_SLANG_ABBREVIATIONS_DIRECTORY, \"slang.csv\")\n",
        "# ------------- </Chat Slang Abbreviations Acronyms dataset> ------------- #\n",
        "\n",
        "# ------------- </English Unigram Frequency dataset> ------------- #\n",
        "ENGLISH_FREQ_DIRECTORY = os.path.join(DRIVE_PREFIX, \"Unigram Frequency\")\n",
        "ENGLISH_FREQ_DATASET = os.path.join(ENGLISH_FREQ_DIRECTORY, \"unigram_freq.csv\")\n",
        "# ------------- </English Unigram Frequency dataset> ------------- #\n",
        "\n",
        "# ------------- <supplied (perverted justice) dataset> ------------- #\n",
        "PERVERTED_JUSTICE_DATASET = os.path.join(DRIVE_PREFIX, \"GeneralData\")\n",
        "PERVERTED_JUSTICE_PREDATOR_CHATS_PATHS = []\n",
        "for chat_path in os.listdir(PERVERTED_JUSTICE_DATASET):\n",
        "    if chat_path.endswith(\".xml\"):\n",
        "        PERVERTED_JUSTICE_PREDATOR_CHATS_PATHS.append(os.path.join(PERVERTED_JUSTICE_DATASET, chat_path))\n",
        "# ------------- </supplied (perverted justice) dataset> ------------- #\n",
        "\n",
        "# ------------- <Stop words dataset> ------------- #\n",
        "\n",
        "STOP_WORDS_DIRECTORY = os.path.join(DRIVE_PREFIX, 'All English Stopwords (700+)')\n",
        "STOP_WORDS_DATASET = os.path.join(STOP_WORDS_DIRECTORY, 'stopwords_All_English_Stopwords_700.txt')\n",
        "\n",
        "# ------------- </Stop words dataset> ------------- #\n",
        "\n",
        "# ------------- <After Preprocessing> ------------- #\n",
        "\n",
        "CLEANED_DIRECTORY = os.path.join(DRIVE_PREFIX, 'cleaned_datasets')\n",
        "CLEANED_PAN12_TRAIN_DATA = os.path.join(CLEANED_DIRECTORY, \"cleaned_train_data.xml\")\n",
        "CLEANED_PAN12_TEST_DATA = os.path.join(CLEANED_DIRECTORY, \"cleaned_test_data.xml\")\n",
        "CLEANED_PERVERTED_JUSTICE_DATA = os.path.join(CLEANED_DIRECTORY, \"cleaned_perverted_justice_data.xml\")\n",
        "\n",
        "# ------------- </After Preprocessing> ------------- #\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LiUEGi9Bq3s5"
      },
      "source": [
        "# Extracting Relavant data from training/testing\n",
        "Converting the raw information into useful datasets"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZL2iRDRmrZqU"
      },
      "source": [
        "## Supplied (perverted justice) Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h7b1ltJJscXg"
      },
      "outputs": [],
      "source": [
        "def extract_field_text(currnet_et, fields):\n",
        "    if type(fields) is not list:\n",
        "        fields = [fields]\n",
        "\n",
        "    for field in fields:\n",
        "        currnet_et = currnet_et.find(field)\n",
        "        if currnet_et is None:\n",
        "            return \"\"\n",
        "    return currnet_et.text\n",
        "\n",
        "\n",
        "class ChatUser:\n",
        "    def __init__(self, person_et):\n",
        "        self.firstname = extract_field_text(person_et, \"FIRSTNAME\")\n",
        "        self.lastname = extract_field_text(person_et, \"LASTNAME\")\n",
        "        self.statedname = extract_field_text(person_et, \"STATEDNAME\")\n",
        "        self.statedage = extract_field_text(person_et, \"STATEDAGE\")\n",
        "        self.age = extract_field_text(person_et, \"AGE\")\n",
        "        self.gender = extract_field_text(person_et, \"GENDER\")\n",
        "        self.screenname = extract_field_text(person_et, [\"SCREENNAME\", \"USERNAME\"])\n",
        "    \n",
        "    def __str__(self):\n",
        "        return \"\\n\".join([\n",
        "                    f\"firstname: {self.firstname}\",\n",
        "                    f\"lastname: {self.lastname}\",\n",
        "                    f\"statedname: {self.statedname}\",\n",
        "                    f\"age: {self.age}\",\n",
        "                    f\"gender: {self.gender}\",\n",
        "                    f\"screenname: {self.screenname}\",\n",
        "                ])\n",
        "\n",
        "class Predator(ChatUser):\n",
        "    def __init__(self, predator_et):\n",
        "        super(Predator, self).__init__(predator_et)\n",
        "        self.truthfulname = extract_field_text(predator_et, \"TRUTHFULNAME\")\n",
        "        self.repeatoffender = extract_field_text(predator_et, \"REPEATOFFENDER\")\n",
        "        self.admitguilty = extract_field_text(predator_et, \"ADMITGUILT\")\n",
        "\n",
        "    def __str__(self):\n",
        "        return \"\\n\".join([\n",
        "                    super(Predator, self).__str__(),\n",
        "                    f\"truthfulname: {self.truthfulname}\",\n",
        "                    f\"repeatoffender: {self.repeatoffender}\",\n",
        "                    f\"admitguilty: {self.admitguilty}\",\n",
        "                ])\n",
        "\n",
        "class Victim(ChatUser):\n",
        "    def __init__(self, victim_et):\n",
        "        super(Victim, self).__init__(victim_et)\n",
        "\n",
        "\n",
        "def extract_from_pj_file(root_et):\n",
        "    predator = Predator(root_et.find(\"PREDATOR\"))\n",
        "    victim = Victim(root_et.find(\"VICTIM\"))\n",
        "    chat_id = (predator.screenname, victim.screenname)\n",
        "    posts = []\n",
        "    for i, post_et in enumerate(root_et.findall(\"POST\")):\n",
        "        username = extract_field_text(post_et, \"USERNAME\")\n",
        "        date = extract_field_text(post_et, \"DATETIME\")\n",
        "        msg = extract_field_text(post_et, \"BODY\")\n",
        "        posts.append((i, username, date, msg))\n",
        "\n",
        "    return chat_id, posts, predator, victim\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bZlOTP1frfKd"
      },
      "outputs": [],
      "source": [
        "# Iterate over conversation to extract useful information to use for training and testing later\n",
        "pj_users = {}\n",
        "pj_predatorial_chats = {}\n",
        "\n",
        "for chat_path in PERVERTED_JUSTICE_PREDATOR_CHATS_PATHS:\n",
        "    root = ET.parse(chat_path).getroot()\n",
        "    chat_id, chat, predator, victim = extract_from_pj_file(root)\n",
        "\n",
        "    pj_predatorial_chats[chat_id] = chat\n",
        "    pj_users[predator.screenname] = predator\n",
        "    pj_users[victim.screenname] = victim\n",
        "\n",
        "pj_predator_usernames = set()\n",
        "pj_victim_usernames = set()\n",
        "for username, user in pj_users.items():\n",
        "    if isinstance(user, Predator):\n",
        "        pj_predator_usernames.add(username)\n",
        "    else:\n",
        "        pj_victim_usernames.add(username)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MEJKsj0-q78Q"
      },
      "source": [
        "## PAN12 Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2e1GHmN4rCTc"
      },
      "outputs": [],
      "source": [
        "def extract_predators_ids_from_pan12(filepath):\n",
        "    pan12_predators = set()\n",
        "    with open(filepath, \"r\") as f:\n",
        "        for predator_id in f:\n",
        "            pan12_predators.add(predator_id.strip())\n",
        "    return pan12_predators\n",
        "\n",
        "def extract_chats_from_pan12_conversation(conversation_et):\n",
        "    chats_msgs = []\n",
        "    participants = set()\n",
        "    for i, message_et in enumerate(conversation_et.findall(\"message\")):\n",
        "        author = extract_field_text(message_et, \"author\")\n",
        "        msg = extract_field_text(message_et, \"text\")\n",
        "        date = extract_field_text(message_et, \"time\")\n",
        "        chats_msgs.append((i, author, date, msg))\n",
        "        participants.add(author)\n",
        "\n",
        "    return tuple(participants), chats_msgs\n",
        "\n",
        "\n",
        "def extract_chats_from_pan12(filepath):\n",
        "    pan_chats = {}\n",
        "    root = ET.parse(filepath).getroot()\n",
        "    conversations = root.find(\"conversations\")\n",
        "    for conversation_et in root.findall(\"conversation\"):\n",
        "        participants, chats_msgs = extract_chats_from_pan12_conversation(conversation_et)\n",
        "        pan_chats[participants] = chats_msgs\n",
        "\n",
        "    return pan_chats\n",
        "\n",
        "\n",
        "def extract_victim_ids(chats):\n",
        "    victims = set()\n",
        "    for participants, chat in chats.items():\n",
        "        for id in participants:\n",
        "            if id not in pan_train_predators_ids:\n",
        "                victims.add(id)\n",
        "    return victims\n",
        "\n",
        "\"\"\"\n",
        "<conversations>\n",
        "<conversation id=\"alsdjflsakhf31323243\">\n",
        "<message>\n",
        "<author>1209839387498sijdf983247</author>\n",
        "<text>Hi little boy</text>\n",
        "<time>12:10</time>\n",
        "</message>\n",
        "<message>\n",
        "...\n",
        "</message>\n",
        "</conversation>\n",
        "<conversation id=\"alsdjflsakhf31323243\">\n",
        "....\n",
        "</conversation>\n",
        "</conversations>\n",
        "\"\"\"\n",
        "\n",
        "pan_train_predators_ids = extract_predators_ids_from_pan12(PAN12_TRAINING_PREDATORS)\n",
        "pan_test_predators_ids = extract_predators_ids_from_pan12(PAN12_TEST_PREDATORS)\n",
        "\n",
        "pan_train_chats = extract_chats_from_pan12(PAN12_TRAINING_CHATS)\n",
        "pan_test_chats = extract_chats_from_pan12(PAN12_TEST_CHATS)\n",
        "\n",
        "pan_train_victims_ids = extract_victim_ids(pan_train_chats)\n",
        "pan_test_victims_ids = extract_victim_ids(pan_test_chats)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4HWLyxOjMSwE"
      },
      "source": [
        "## Overview so far"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N5XHUWHv6YRO"
      },
      "outputs": [],
      "source": [
        "# ---------- <What we have so far?> ---------- #\n",
        "overview_so_far =\"\"\"\n",
        "pj_users -> dict[username]: ChatUser\n",
        "pj_predator_usernames -> set(pj_predator_usernames)\n",
        "pj_victim_usernames -> set(pj_victim_usernames)\n",
        "pj_predatorial_chats -> dict[(predator_username, victim_username)]: list((i, username, date, msg))\n",
        "\n",
        "pan_train_predators_ids -> set(predator_train_usernames)\n",
        "pan_test_predators_ids -> set(predator_test_usernames)\n",
        "pan_train_victims_ids -> set(victim_train_usernames)\n",
        "pan_test_victims_ids -> set(victim_test_usernames)\n",
        "pan_train_chats -> dict[tuple(train_side_a_username, train_side_b_username, ...)]: list((i, username, date, msg))\n",
        "pan_test_chats -> dict[tuple(test_side_a_username, test_side_b_username, ...)]: list((i, username, date, msg))\n",
        "\"\"\"\n",
        "# ---------- </What we have so far?> ---------- #\n",
        "\n",
        "# ---------- <What we want to end up with?> ---------- #\n",
        "target_datasets =\"\"\"\n",
        "train_x -> list(chats - tokenize)\n",
        "train_y -> list(label: predatorial chat or not)\n",
        "test_x -> list(chats - tokenize)\n",
        "test_y -> list(label: predatorial chat or not)\n",
        "\"\"\"\n",
        "# ---------- </What we want to end up with?> ---------- #"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S3x-4RcJAp3Q",
        "outputId": "53552e25-4b7f-4157-c2ef-76c64fe9d900"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "pj_predatorial_chats\n",
            "participants: ('tunnels12000', 'tracy_in_xcess')\n",
            "few messages: [(0, 'tunnels12000', '07/19/06  7:48:24 PM', 'hi'), (1, 'tracy_in_xcess', '(07/19/06  7:49:06 PM)', 'hi'), (2, 'tunnels12000', '07/19/06  7:49:09 PM', 'very pretty pic')] ...\n",
            "\n",
            "pan_train_chats\n",
            "participants: ('0158d0d6781fc4d493f243d4caa49747', '97964e7a9e8eb9cf78f2e4d7b2ff34c7')\n",
            "few messages: [(0, '97964e7a9e8eb9cf78f2e4d7b2ff34c7', '03:20', 'Hola.'), (1, '0158d0d6781fc4d493f243d4caa49747', '03:20', 'hi.'), (2, '0158d0d6781fc4d493f243d4caa49747', '03:20', 'whats up?')] ...\n",
            "\n",
            "pan_test_chats\n",
            "participants: ('b8810fee2f4a71f849f3f7409546d1d9', '60659cfda992013e610f285c46692d28', 'b25b6b77a0087ff8385941e5545d32ea', '0a39f78bcb297ab0ebe8a29c28bfed89', 'edb259c0e0038f38bb200bc20c8cbf7e')\n",
            "few messages: [(0, '0a39f78bcb297ab0ebe8a29c28bfed89', '15:24', 'bugmail: [Bug 6978] New: Mark eof-terminated script elements as malformed &lt;http://lists.w3.org/Archives/Public/public-html-bugzilla/2009May/0049.html&gt;'), (1, '60659cfda992013e610f285c46692d28', '15:32', 'Henri, can I ask you a Firefox build question (Windows)?'), (2, 'b8810fee2f4a71f849f3f7409546d1d9', '15:34', \"60659cfda992013e610f285c46692d28: sure, but I probably don't know the answer\")] ...\n",
            "\n",
            "pj_predator_usernames\n",
            "['sphinx_56_02', 'i_smoke_alotta_weed']\n",
            "\n",
            "pj_victim_usernames\n",
            "['chels_m1993', 'jess_n_cali']\n",
            "\n",
            "pan_train_predators_ids\n",
            "['3e48ec4a22b6f1f5b9a5bd991583294c', '7fc0a10ac4f945ebf4004b258179ad1c']\n",
            "\n",
            "pan_train_victims_ids\n",
            "['0dbfef49828f003414a0abee51eb7bd9', '7b3cb2d835d0beff80b19bd87a686e83']\n",
            "\n",
            "pan_test_victims_ids\n",
            "['890da0409355d4d67403ba18fab8157b', '59160e1af9472d28465bf3bd109fc9e5']\n",
            "\n",
            "pan_test_predators_ids\n",
            "['87eb0510ab6472e60cd0927b83efd695', '016b081eb8a3c4f7f952757bb83fe5e3']\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# ---------- <Samples per object> ---------- #\n",
        "def print_sample_chat_dict(chats):\n",
        "    for k, v in chats.items():\n",
        "        print(f\"participants: {k}\")\n",
        "        print(f\"few messages: {v[0:3]} ...\")\n",
        "        print()\n",
        "        break\n",
        "\n",
        "print(\"pj_predatorial_chats\")\n",
        "print_sample_chat_dict(pj_predatorial_chats)\n",
        "\n",
        "print(\"pan_train_chats\")\n",
        "print_sample_chat_dict(pan_train_chats)\n",
        "\n",
        "print(\"pan_test_chats\")\n",
        "print_sample_chat_dict(pan_test_chats)\n",
        "\n",
        "print(\"pj_predator_usernames\")\n",
        "print(f\"{list(pj_predator_usernames)[0:2]}\")\n",
        "print()\n",
        "\n",
        "print(\"pj_victim_usernames\")\n",
        "print(f\"{list(pj_victim_usernames)[0:2]}\")\n",
        "print()\n",
        "\n",
        "print(\"pan_train_predators_ids\")\n",
        "print(f\"{list(pan_train_predators_ids)[0:2]}\")\n",
        "print()\n",
        "\n",
        "print(\"pan_train_victims_ids\")\n",
        "print(f\"{list(pan_train_victims_ids)[0:2]}\")\n",
        "print()\n",
        "\n",
        "print(\"pan_test_victims_ids\")\n",
        "print(f\"{list(pan_test_victims_ids)[0:2]}\")\n",
        "print()\n",
        "\n",
        "print(\"pan_test_predators_ids\")\n",
        "print(f\"{list(pan_test_predators_ids)[0:2]}\")\n",
        "print()\n",
        "\n",
        "# ---------- </Samples per object> ---------- #"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RG8ybBUY6VAl"
      },
      "source": [
        "# EDA (Can Be Skipped for Actual Training & Testings)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xjI6b3K6J1pg",
        "outputId": "f37e0ed2-e185-43ef-d47f-a131f6f53668"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "10.00%\n"
          ]
        }
      ],
      "source": [
        "def get_precentage_str(amount, total):\n",
        "    return f\"{(amount / total) * 100:0.2f}%\"\n",
        "\n",
        "print(get_precentage_str(10,100)) # test\n",
        "\n",
        "def calculate_average_msgs_count(chats):\n",
        "    total_messages = 0\n",
        "    for participants, posts in chats.items():\n",
        "        total_messages += len(posts)\n",
        "\n",
        "    return  int(total_messages / len(chats))\n",
        "\n",
        "def data_graph():\n",
        "  fsd\n",
        "  pass"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6LJ7YMETNgO4"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ih3XgU5x86Gf"
      },
      "source": [
        "## Perverted Justice's EDA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9C12bkd28P3D",
        "outputId": "7c9bbc36-0c6a-4666-b23f-e614e3806300"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Perverted Justice's EDA\n",
            "------------------------\n",
            "\n",
            "Different users: 110\n",
            "Total Chats (predatorial only): 56\n",
            "Predator users: 56 / 110 (50.91%)\n",
            "Victim users: 54 / 110 (49.09%)\n",
            "Predatorial chats: 56\n",
            "Average amount of messages per chat: 1387\n"
          ]
        }
      ],
      "source": [
        "print(f\"Perverted Justice's EDA\")\n",
        "print(f\"------------------------\")\n",
        "print()\n",
        "print(f\"Different users: {len(pj_users)}\")\n",
        "print(f\"Total Chats (predatorial only): {len(pj_predatorial_chats)}\")\n",
        "print(f\"Predator users: {len(pj_predator_usernames)} / {len(pj_users)} ({get_precentage_str(len(pj_predator_usernames), len(pj_users))})\")\n",
        "print(f\"Victim users: {len(pj_victim_usernames)} / {len(pj_users)} ({get_precentage_str(len(pj_victim_usernames), len(pj_users))})\")\n",
        "print(f\"Predatorial chats: {len(pj_predatorial_chats)}\")\n",
        "print(f\"Average amount of messages per chat: {calculate_average_msgs_count(pj_predatorial_chats)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PXR1kRDcDC9g"
      },
      "source": [
        "## PAN12's EDA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7kdWNtDBHqa1"
      },
      "outputs": [],
      "source": [
        "def amount_of_predatorial_messages(chats, predators_ids):\n",
        "    predetorial_chats_count = 0\n",
        "    for participants, posts in chats.items():\n",
        "        for p in participants:\n",
        "            if p in predators_ids:\n",
        "                predetorial_chats_count += 1\n",
        "                break\n",
        "    return predetorial_chats_count\n",
        "\n",
        "def calculate_predator_average_msgs_count(chats, predators_ids):\n",
        "    predetorial_chats_count = 0\n",
        "    predetorial_chats_total_msgs = 0\n",
        "    for participants, posts in chats.items():\n",
        "        for p in participants:\n",
        "            if p in predators_ids:\n",
        "                predetorial_chats_count += 1\n",
        "                predetorial_chats_total_msgs += len(posts)\n",
        "                break\n",
        "    return predetorial_chats_total_msgs / predetorial_chats_count"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GCvSOS3-DGId",
        "outputId": "88ac9d3c-29da-44b1-924a-8dd8c4775e30"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "PAN12's EDA\n",
            "------------\n",
            "\n",
            "-- Train --\n",
            "Different users: 97689\n",
            "Predator users: 142/97689 (0.15%)\n",
            "Victim users: 97547/97689 (99.85%)\n",
            "Predatorial chats: 250/55353 (0.45%)\n",
            "Average amount of messages per chat: 14\n",
            "Average amount of messages per predatorial chat: 71.04\n",
            "\n",
            "-- Test --\n",
            "Different users: 218954\n",
            "Predator users: 254/218954 (0.12%)\n",
            "Victim users: 218700/218954 (99.88%)\n",
            "Predatorial chats: 453/127216 (0.36%)\n",
            "Average amount of messages per chat: 14\n",
            "Average amount of messages per predatorial chat: 39.45\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print(f\"PAN12's EDA\")\n",
        "print(f\"------------\")\n",
        "print()\n",
        "total_users_train = len(pan_train_victims_ids) + len(pan_train_predators_ids)\n",
        "total_users_test = len(pan_test_victims_ids) + len(pan_test_predators_ids)\n",
        "train_predatorial_chats_count = amount_of_predatorial_messages(pan_train_chats, pan_train_predators_ids)\n",
        "test_predatorial_chats_count = amount_of_predatorial_messages(pan_test_chats, pan_test_predators_ids)\n",
        "train_average_ = calculate_average_msgs_count(pan_train_chats)\n",
        "\n",
        "\n",
        "print(\"-- Train --\")\n",
        "print(f\"Different users: {total_users_train}\")\n",
        "print(f\"Predator users: {len(pan_train_predators_ids)}/{total_users_train} ({get_precentage_str(len(pan_train_predators_ids), total_users_train)})\")\n",
        "print(f\"Victim users: {len(pan_train_victims_ids)}/{total_users_train} ({get_precentage_str(len(pan_train_victims_ids), total_users_train)})\")\n",
        "print(f\"Predatorial chats: {train_predatorial_chats_count}/{len(pan_train_chats)} ({get_precentage_str(train_predatorial_chats_count, len(pan_train_chats))})\")\n",
        "print(f\"Average amount of messages per chat: {calculate_average_msgs_count(pan_train_chats)}\")\n",
        "print(f\"Average amount of messages per predatorial chat: {calculate_predator_average_msgs_count(pan_train_chats, pan_train_predators_ids):0.2f}\")\n",
        "print()\n",
        "\n",
        "print(\"-- Test --\")\n",
        "print(f\"Different users: {total_users_test}\")\n",
        "print(f\"Predator users: {len(pan_test_predators_ids)}/{total_users_test} ({get_precentage_str(len(pan_test_predators_ids), total_users_test)})\")\n",
        "print(f\"Victim users: {len(pan_test_victims_ids)}/{total_users_test} ({get_precentage_str(len(pan_test_victims_ids), total_users_test)})\")\n",
        "print(f\"Predatorial chats: {test_predatorial_chats_count}/{len(pan_test_chats)} ({get_precentage_str(test_predatorial_chats_count, len(pan_test_chats))})\")\n",
        "print(f\"Average amount of messages per chat: {calculate_average_msgs_count(pan_test_chats)}\")\n",
        "print(f\"Average amount of messages per predatorial chat: {calculate_predator_average_msgs_count(pan_test_chats, pan_test_predators_ids):0.2f}\")\n",
        "print()\n",
        "\n",
        "# print(f\"TRAIN: Predatorial chats: {len(pan_train_chats)}\")\n",
        "# print(f\"TEST: Predatorial chats: {len(pan_test_chats)}\")\n",
        "\n",
        "# print(f\"TRAIN: Average amount of messages for predatorial chat: {calculate_average_msgs_count(pan_train_chats)}\")\n",
        "# print(f\"TEST: Average amount of messages for predatorial chat: {calculate_average_msgs_count(pan_test_chats)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JzYYw1v4La5c"
      },
      "source": [
        "# Preprocess - Getting ready to tokenize"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Started With\")\n",
        "print(overview_so_far)\n",
        "print(\"End with\")\n",
        "print(target_datasets)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bGN5mvziVntx",
        "outputId": "9e9f05cd-98aa-4fe4-cb09-9b3214c21de1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Started With\n",
            "\n",
            "pj_users -> dict[username]: ChatUser\n",
            "pj_predator_usernames -> set(pj_predator_usernames)\n",
            "pj_victim_usernames -> set(pj_victim_usernames)\n",
            "pj_predatorial_chats -> dict[(predator_username, victim_username)]: list((i, username, date, msg))\n",
            "\n",
            "pan_train_predators_ids -> set(predator_train_usernames)\n",
            "pan_test_predators_ids -> set(predator_test_usernames)\n",
            "pan_train_victims_ids -> set(victim_train_usernames)\n",
            "pan_test_victims_ids -> set(victim_test_usernames)\n",
            "pan_train_chats -> dict[tuple(train_side_a_username, train_side_b_username, ...)]: list((i, username, date, msg))\n",
            "pan_test_chats -> dict[tuple(test_side_a_username, test_side_b_username, ...)]: list((i, username, date, msg))\n",
            "\n",
            "End with\n",
            "\n",
            "train_x -> list(chats - tokenize)\n",
            "train_y -> list(label: predatorial chat or not)\n",
            "test_x -> list(chats - tokenize)\n",
            "test_y -> list(label: predatorial chat or not)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-hRaj7HvO3sK"
      },
      "outputs": [],
      "source": [
        "def concatinate_following_user_messages(chats):\n",
        "    \"\"\"\n",
        "    Step 1\n",
        "    turining:\n",
        "        A: hi\n",
        "        A: how are you\n",
        "        A: doing\n",
        "        B: fine\n",
        "    into:\n",
        "        A: hi how are you doing\n",
        "        B: fine\n",
        "\n",
        "    Also here we drop the full (i, user, time, text) and left with 'text' only\n",
        "    \"\"\"\n",
        "    \"\"\"\n",
        "    we might want to consider leaving some message seprestae if along time had passed between the last message \n",
        "    \"\"\"\n",
        "    cat_chats = {}\n",
        "    for participants, messages in chats.items():\n",
        "        cat_chats[participants] = []\n",
        "        current_speaker = None\n",
        "        current_following_messages = \"\"\n",
        "        for i, user, time, text in messages:\n",
        "            if text is None or len(text) == 0:\n",
        "                # passing over empty text messages\n",
        "                continue\n",
        "            elif current_speaker is None:\n",
        "                # new speaker begin concatinating messages\n",
        "                current_speaker = user\n",
        "                current_following_messages = text\n",
        "            elif user == current_speaker:\n",
        "                # concatinating the messages\n",
        "                current_following_messages = \" \".join([current_following_messages, text])\n",
        "            elif current_following_messages:\n",
        "                # new user talking\n",
        "                cat_chats[participants].append(current_following_messages)\n",
        "                current_following_messages = \"\"\n",
        "                current_speaker = user\n",
        "    return cat_chats\n",
        "\n",
        "\n",
        "def remove_empty_chats(chats):\n",
        "    \"\"\"\n",
        "    Step 2 - Removing empty conversations or one-person conversations\n",
        "    \"\"\"\n",
        "    clean_chats = {}\n",
        "    for participants, messages in chats.items():\n",
        "        if len(list(participants)) < 2 or len(list(participants)) > 3:\n",
        "            # remove only one participant chats\n",
        "            continue\n",
        "        \n",
        "        if len(messages) < 2:\n",
        "            # remove 1 message chats\n",
        "            continue\n",
        "        \n",
        "        clean_chats[participants] = messages\n",
        "    return clean_chats\n",
        "\n",
        "\n",
        "def decode_xml_encoded(chats):\n",
        "    \"\"\"\n",
        "    Step 3\n",
        "    In order to parse XML raw dataset we needed to escape special XML chars\n",
        "    we now replace them with the original characters.\n",
        "    from: Me &amp; you\n",
        "    to: Me & you\n",
        "    This will make it easier to drop punctuations later\n",
        "    \"\"\"\n",
        "    clean_chats = {}\n",
        "    for participants, messages in chats.items():\n",
        "        clean_chats[participants] = []\n",
        "        for text in messages:\n",
        "            clean_chats[participants].append(text.replace(\"&amp;\",\"&\").replace(\"&lt;\",\"<\").replace(\"&gt;\",\">\"))\n",
        "    return clean_chats\n",
        "\n",
        "def remove_puctuation(chats):\n",
        "    \"\"\"\n",
        "    Step 4\n",
        "    Puncuations are known to not add much value and so we remove them here\n",
        "    \"\"\"\n",
        "    clean_chats = {}\n",
        "    for participants, messages in chats.items():\n",
        "        clean_chats[participants] = []\n",
        "        for text in messages:\n",
        "            new_text = text.translate(str.maketrans('', '', string.punctuation))\n",
        "            clean_chats[participants].append(new_text)\n",
        "    return clean_chats\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q2h-5raah6TP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "74609938-b49c-4735-a5a8-6a398397d6fa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/wordnet.zip.\n",
            "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/omw-1.4.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        }
      ],
      "source": [
        "# ---------- <for the un-abbreviation task - type 1> ---------- #\n",
        "UNABBREVIATE_TYPE = 1\n",
        "TOP_FREQUENT_WORDS = 2000\n",
        "BLACKLIST_SKIPP_ABBREVIATE = [\"im\", \"laser\"]\n",
        "\n",
        "\n",
        "chat_slang_df_csv  = pd.read_csv(CHAT_SLANG_ABBREVIATIONS_DATASET)\n",
        "unabbreviation_mappings = {}\n",
        "unabbreviated = set()\n",
        "for _, row in chat_slang_df_csv.iterrows():\n",
        "    unabbreviation_mappings[row['acronym']] = row['expansion']\n",
        "\n",
        "english_freq_df_csv = pd.read_csv(ENGLISH_FREQ_DATASET)\n",
        "english_words_to_freq_mappings = {}\n",
        "for i, row in english_freq_df_csv.iterrows():\n",
        "    if i > TOP_FREQUENT_WORDS:\n",
        "        break\n",
        "    english_words_to_freq_mappings[row['word']] = row['count']\n",
        "\n",
        "nltk.download('wordnet')\n",
        "nltk.download('omw-1.4')\n",
        "nltk.download('stopwords')\n",
        "STOPWORDS = nltk.corpus.stopwords.words('english')\n",
        "LEMMATIZER = WordNetLemmatizer()\n",
        "\n",
        "\n",
        "del english_freq_df_csv\n",
        "del chat_slang_df_csv\n",
        "# ---------- </for the un-abbreviation task - type 1> ---------- #\n",
        "\n",
        "def should_abbreviate(abbr, full_words):\n",
        "    for word in full_words:\n",
        "        try:\n",
        "            if english_words_to_freq_mappings[abbr] > english_words_to_freq_mappings[word]:\n",
        "                # the abbr is a more frequent word than one of the words in the proposed fix\n",
        "                return False\n",
        "        except KeyError:\n",
        "            if abbr in english_words_to_freq_mappings and word not in english_words_to_freq_mappings:\n",
        "                # fix is not even in top TOP_FREQUENT_WORDS while abbr is\n",
        "                return False\n",
        "    return True\n",
        "\n",
        "def unabbreviate_text_type_one(text):\n",
        "    output_words = []\n",
        "    for word in text.split(' '):\n",
        "        if word in unabbreviation_mappings:\n",
        "            proposed_fix = unabbreviation_mappings[word]\n",
        "            if should_abbreviate(word, proposed_fix.split(\" \")) and word not in BLACKLIST_SKIPP_ABBREVIATE:\n",
        "                output_words.append(proposed_fix)\n",
        "                # if word not in unabbreviated:\n",
        "                #     unabbreviated.add(word)\n",
        "                #     print(f\"Expanded: {word} -> {proposed_fix}\")\n",
        "                continue\n",
        "        output_words.append(word)\n",
        "    return \" \".join(output_words)\n",
        "    \n",
        "\n",
        "def unabbreviate_text_type_two(text):\n",
        "    import openai\n",
        "    openai.api_key = \"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\"\n",
        "    response = openai.Completion.create(\n",
        "            model=\"text-davinci-002\",\n",
        "            prompt=f\"Unabbreviate this sentence: \\\"{text}\\\"\",\n",
        "            temperature=0.7,\n",
        "            max_tokens=256,\n",
        "            top_p=1,\n",
        "            frequency_penalty=0,\n",
        "            presence_penalty=0\n",
        "        )\n",
        "    return response.to_dict()['choices'][0].to_dict()['text'].strip()\n",
        "\n",
        "\n",
        "def unabbriviate_text(text):\n",
        "    if UNABBREVIATE_TYPE == 1:\n",
        "        # NOTE: did not catch stuff like \"feel rlly nice\" since he did not know \"rlly\" is really however type 2 - did manage to know\n",
        "        return unabbreviate_text_type_one(text)\n",
        "    return unabbreviate_text_type_two(text)\n",
        "\n",
        "\n",
        "def unabbriviate_chats(chats):\n",
        "    \"\"\"\n",
        "    Step 5\n",
        "    Turning:\n",
        "        A: why r u like that?\n",
        "    Into:\n",
        "        A: why are you like that?\n",
        "    \"\"\"\n",
        "    clean_chats = {}\n",
        "    for participants, messages in chats.items():\n",
        "        clean_chats[participants] = []\n",
        "        for text in messages:\n",
        "             clean_chats[participants].append(unabbriviate_text(text))\n",
        "    return clean_chats\n",
        "\n",
        "def remove_stop_words(chats):\n",
        "    \"\"\"\n",
        "    Step 6\n",
        "    Removing stop words that will not add much information about the chat.\n",
        "    Does a few other final things:\n",
        "    1. Also transforms everything into lower case\n",
        "    2. remove URLs (http...)\n",
        "    \"\"\"\n",
        "    clean_chats = {}\n",
        "    for participants, messages in chats.items():\n",
        "        clean_chats[participants] = []\n",
        "        for text in messages:\n",
        "            cleaned_text = \" \".join([word.lower() for word in text.split() if word.lower() not in STOPWORDS and \"http\" not in word.lower()])\n",
        "            if len(cleaned_text):\n",
        "                clean_chats[participants].append(cleaned_text)\n",
        "    return clean_chats\n",
        "\n",
        "\n",
        "def lemmatize_words(chats):\n",
        "    \"\"\"\n",
        "    Step 7\n",
        "    Will help with TF-IDF\n",
        "    tranform: \"children\" -> \"child\"\n",
        "              \"child\" -> \"child\"\n",
        "    \"\"\"\n",
        "    clean_chats = {}\n",
        "    for participants, messages in chats.items():\n",
        "        clean_chats[participants] = []\n",
        "        for text in messages:\n",
        "            cleaned_text = \" \".join([LEMMATIZER.lemmatize(word) for word in text.split()])\n",
        "            clean_chats[participants].append(cleaned_text)\n",
        "    return clean_chats"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tbaA9CqLrsPi"
      },
      "outputs": [],
      "source": [
        "def process_raw_dataset(raw_dataset):\n",
        "    # Step 1\n",
        "    out_dataset = concatinate_following_user_messages(raw_dataset)\n",
        "    # Step 2\n",
        "    out_dataset = remove_empty_chats(out_dataset)\n",
        "    # Step 3\n",
        "    out_dataset = decode_xml_encoded(out_dataset)\n",
        "    # Step 4\n",
        "    out_dataset = remove_puctuation(out_dataset)\n",
        "    # Step 5\n",
        "    out_dataset = unabbriviate_chats(out_dataset)\n",
        "    # Step 6\n",
        "    out_dataset = remove_stop_words(out_dataset)\n",
        "    # Step 7\n",
        "    out_dataset = lemmatize_words(out_dataset)\n",
        "\n",
        "    return out_dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GDnExd1nLjAm"
      },
      "source": [
        "## PAN12"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_5_Tan4YOCQ6"
      },
      "outputs": [],
      "source": [
        "pan_cleaned_train_dataset = process_raw_dataset(pan_train_chats)\n",
        "pan_cleaned_test_dataset = process_raw_dataset(pan_test_chats)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2FHWvGB2LlgG"
      },
      "source": [
        "## Perverted Justice"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O_fKiGFYLnkr"
      },
      "outputs": [],
      "source": [
        "pj_predatorial_cleaned_dataset = process_raw_dataset(pj_predatorial_chats)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Save & Load Cleaned Datasets (Post pre-process)"
      ],
      "metadata": {
        "id": "XF282_rn0tmJ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2ygaZVpMwDou"
      },
      "outputs": [],
      "source": [
        "# Saved dataset as XML\n",
        "def export_to_xml(dataset, xml_file):\n",
        "    dataset_et = ET.Element('dataset')\n",
        "    for participants, messages in dataset.items():\n",
        "        specific_chat = ET.SubElement(dataset_et, f\"chat\", attrib={f\"id{i}\": p for i, p in enumerate(participants)})\n",
        "        for message in messages:\n",
        "            msg = ET.SubElement(specific_chat, \"message\")\n",
        "            msg.text = escape(message)\n",
        "\n",
        "    dataset_et_tree = ET.ElementTree(dataset_et)\n",
        "    dataset_et_tree.write(xml_file)\n",
        "\n",
        "export_to_xml(pan_cleaned_train_dataset, CLEANED_PAN12_TRAIN_DATA)\n",
        "export_to_xml(pan_cleaned_test_dataset, CLEANED_PAN12_TEST_DATA)\n",
        "export_to_xml(pj_predatorial_cleaned_dataset, CLEANED_PERVERTED_JUSTICE_DATA)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# load datasets from XMLs\n",
        "def load_dataset(xml_file):\n",
        "    output_dataset = {}\n",
        "    root_et = ET.parse(xml_file).getroot()\n",
        "    for chat_et in root_et.findall(\"chat\"):\n",
        "        participants = []\n",
        "        for i in range(10):\n",
        "            current_p = chat_et.get(f\"id{i}\")\n",
        "            if current_p is None:\n",
        "                break\n",
        "            participants.append(current_p)\n",
        "        \n",
        "        participants = tuple(participants)\n",
        "        output_dataset[participants] = []\n",
        "        for message_et in chat_et.findall(\"message\"):\n",
        "            output_dataset[participants].append(unescape(message_et.text))\n",
        "    return output_dataset\n",
        "\n",
        "\n",
        "pan_cleaned_train_dataset = load_dataset(CLEANED_PAN12_TRAIN_DATA)\n",
        "pan_cleaned_test_dataset = load_dataset(CLEANED_PAN12_TEST_DATA)\n",
        "pj_predatorial_cleaned_dataset = load_dataset(CLEANED_PERVERTED_JUSTICE_DATA)"
      ],
      "metadata": {
        "id": "wXwwDU001Kip"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model"
      ],
      "metadata": {
        "id": "SPPQPFDvgWo4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "pj_users -> dict[username]: ChatUser\n",
        "pj_predator_usernames -> set(pj_predator_usernames)\n",
        "pj_victim_usernames -> set(pj_victim_usernames)\n",
        "pj_predatorial_chats -> dict[(predator_username, victim_username)]: list((i, username, date, msg))\n",
        "\n",
        "pan_train_predators_ids -> set(predator_train_usernames)\n",
        "pan_test_predators_ids -> set(predator_test_usernames)\n",
        "pan_train_victims_ids -> set(victim_train_usernames)\n",
        "pan_test_victims_ids -> set(victim_test_usernames)\n",
        "pan_train_chats -> dict[tuple(train_side_a_username, train_side_b_username, ...)]: list((i, username, date, msg))\n",
        "pan_test_chats -> dict[tuple(test_side_a_username, test_side_b_username, ...)]: list((i, username, date, msg))\n",
        "\n",
        "\"\"\"\n",
        "def create_X_Y_from_cleaned_dataset(cleaned_dataset, predator_usernames):\n",
        "    X = []\n",
        "    Y = []\n",
        "    for participants, messages in cleaned_dataset.items():\n",
        "        if len(messages) == 0:\n",
        "            continue\n",
        "        if any([p in predator_usernames for p in participants]):\n",
        "            Y.append(1)\n",
        "        else:\n",
        "            Y.append(0)\n",
        "        X.append(messages)\n",
        "\n",
        "    return X, Y\n",
        "\n",
        "pan_train_x, pan_train_y = create_X_Y_from_cleaned_dataset(pan_cleaned_train_dataset, pan_train_predators_ids)\n",
        "pan_test_x, pan_test_y = create_X_Y_from_cleaned_dataset(pan_cleaned_test_dataset, pan_test_predators_ids)\n",
        "pj_x, pj_y = create_X_Y_from_cleaned_dataset(pj_predatorial_cleaned_dataset, pj_predator_usernames)\n",
        "\n",
        "# without the preprocess stage\n",
        "dirty_pan_train_x, dirty_pan_train_y = create_X_Y_from_cleaned_dataset(concatinate_following_user_messages(pan_train_chats), pan_train_predators_ids)\n",
        "dirty_pan_test_x, dirty_pan_test_y = create_X_Y_from_cleaned_dataset(concatinate_following_user_messages(pan_test_chats), pan_test_predators_ids)"
      ],
      "metadata": {
        "id": "fYQMwdIrW_FA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## TF-IDF"
      ],
      "metadata": {
        "id": "DMY2qEzSgUw6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn import metrics\n",
        "from imblearn.ensemble import BalancedBaggingClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from imblearn.over_sampling import SMOTE\n",
        "\n",
        "def concat_dataset(dataset_x):\n",
        "    return [\" \".join(x) for x in dataset_x]\n",
        "\n",
        "class TFIDFClassifier():\n",
        "    def __init__(self):\n",
        "        self.naive_bayes_classifier = MultinomialNB()\n",
        "        self.tfidfvectorizer = TfidfVectorizer(analyzer='word', stop_words='english')\n",
        "    \n",
        "    def train(self, train_x, train_y):\n",
        "        train_x = concat_dataset(train_x)\n",
        "        X_train_tf  = self.tfidfvectorizer.fit_transform(train_x)\n",
        "        X_train_tf = self.tfidfvectorizer.transform(train_x)\n",
        "        self.naive_bayes_classifier.fit(X_train_tf, train_y)\n",
        "\n",
        "    def test(self, test_x, test_y):\n",
        "        test_x = concat_dataset(test_x)\n",
        "        X_test_tf = self.tfidfvectorizer.transform(test_x)\n",
        "        y_pred = self.naive_bayes_classifier.predict(X_test_tf)\n",
        "\n",
        "        print(metrics.classification_report(test_y, y_pred, target_names=['Not-Predatorial', 'Predatorial']))\n",
        "        print(f\"F0.5 - {metrics.fbeta_score(test_y, y_pred, beta=0.5):0.4f}\")\n",
        "\n"
      ],
      "metadata": {
        "id": "wbOZtuODgeIm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def undersample_class(train_x, train_y, oversampled_class, target_num_samples=1000):\n",
        "    undersampled_x = []\n",
        "    undersampled_y = []\n",
        "    samples_in_class = 0\n",
        "    for x,y in zip(train_x, train_y):\n",
        "        if y == oversampled_class:\n",
        "            if samples_in_class < target_num_samples:\n",
        "                samples_in_class += 1\n",
        "                undersampled_x.append(x)\n",
        "                undersampled_y.append(y)\n",
        "        else:\n",
        "            undersampled_x.append(x)\n",
        "            undersampled_y.append(y)\n",
        "    \n",
        "    return undersampled_x, undersampled_y"
      ],
      "metadata": {
        "id": "Jvz7W9BFqTYi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import defaultdict\n",
        "def print_train_statistices(x, y):\n",
        "    LABEL_TO_INDICATIVE = {0: 'Non-Predatorial', 1: 'Predatorial'}\n",
        "    labels_hist = {'Non-Predatorial': 0, 'Predatorial': 0}\n",
        "    for sample, label in zip(x,y):\n",
        "        labels_hist[LABEL_TO_INDICATIVE[label]] += 1\n",
        "    \n",
        "    for label, amount in labels_hist.items():\n",
        "        print(f\"{label}: {amount} / {len(x)} ({get_precentage_str(amount, len(x))})\")\n",
        "    \n",
        "        "
      ],
      "metadata": {
        "id": "r1CUVsYNrHHr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def run_TFIDF_classifier_on_PAN():\n",
        "    under_train_x, under_train_y = undersample_class(pan_train_x, pan_train_y, oversampled_class=0, target_num_samples=550) # tested few\n",
        "    model = TFIDFClassifier()\n",
        "    print_train_statistices(under_train_x, under_train_y)\n",
        "    model.train(under_train_x, under_train_y)\n",
        "    model.test(pan_test_x, pan_test_y)\n",
        "\n",
        "def run_TFIDF_classifier_on_Dirty_PAN():\n",
        "    under_train_x, under_train_y = undersample_class(dirty_pan_train_x, dirty_pan_train_y, oversampled_class=0, target_num_samples=550)\n",
        "    model = TFIDFClassifier()\n",
        "    print_train_statistices(under_train_x, under_train_y)\n",
        "    model.train(under_train_x, under_train_y)\n",
        "    model.test(dirty_pan_test_x, dirty_pan_test_y)\n",
        "\n",
        "def run_TFIDF_classifier_on_PAN_TEST_ON_Dirty():\n",
        "    under_train_x, under_train_y = undersample_class(pan_train_x, pan_train_y, oversampled_class=0, target_num_samples=550)\n",
        "    model = TFIDFClassifier()\n",
        "    print_train_statistices(under_train_x, under_train_y)\n",
        "    model.train(under_train_x, under_train_y)\n",
        "    model.test(dirty_pan_test_x, dirty_pan_test_y)\n",
        "\n",
        "def run_TFIDF_classifier_on_PAN_and_PJ():\n",
        "    pj_X_train, pj_X_test, pj_y_train, pj_y_test = train_test_split(pj_x, pj_y, test_size=0.33, random_state=42)\n",
        "    complete_train_x = pan_train_x + pj_X_train\n",
        "    complete_train_y = pan_train_y + pj_y_train\n",
        "    under_train_x, under_train_y = undersample_class(complete_train_x, complete_train_y, oversampled_class=0, target_num_samples=800)\n",
        "    model = TFIDFClassifier()\n",
        "    print_train_statistices(under_train_x, under_train_y)\n",
        "    model.train(under_train_x, under_train_y)\n",
        "    model.test(pan_test_x + pj_X_test, pan_test_y + pj_y_test)"
      ],
      "metadata": {
        "id": "MWLbd3C7ENaa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "run_TFIDF_classifier_on_PAN_and_PJ()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iA08gNGbFGtU",
        "outputId": "72f6774c-cb69-43f8-e687-6aad843b3a66"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                 precision    recall  f1-score   support\n",
            "\n",
            "Not-Predatorial       1.00      1.00      1.00     38693\n",
            "    Predatorial       0.99      0.62      0.77       237\n",
            "\n",
            "       accuracy                           1.00     38930\n",
            "      macro avg       1.00      0.81      0.88     38930\n",
            "   weighted avg       1.00      1.00      1.00     38930\n",
            "\n",
            "F0.5 - 0.8884\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "run_TFIDF_classifier_on_PAN()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NBeX-fBgFqlP",
        "outputId": "53729e87-99d3-4e08-8f23-557d2952d30a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                 precision    recall  f1-score   support\n",
            "\n",
            "Not-Predatorial       1.00      1.00      1.00     38693\n",
            "    Predatorial       0.93      0.70      0.80       218\n",
            "\n",
            "       accuracy                           1.00     38911\n",
            "      macro avg       0.97      0.85      0.90     38911\n",
            "   weighted avg       1.00      1.00      1.00     38911\n",
            "\n",
            "F0.5 - 0.8753\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "run_TFIDF_classifier_on_Dirty_PAN()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PgydwFJwFuzZ",
        "outputId": "b20c829b-a1e4-4bd7-92ba-44b77739c4af"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                 precision    recall  f1-score   support\n",
            "\n",
            "Not-Predatorial       1.00      0.99      1.00    118092\n",
            "    Predatorial       0.21      0.82      0.34       252\n",
            "\n",
            "       accuracy                           0.99    118344\n",
            "      macro avg       0.61      0.91      0.67    118344\n",
            "   weighted avg       1.00      0.99      1.00    118344\n",
            "\n",
            "F0.5 - 0.2495\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "run_TFIDF_classifier_on_PAN_TEST_ON_Dirty()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qfCwq-6bFxKj",
        "outputId": "f9322452-8ed3-45cc-aa19-6ed36476e321"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                 precision    recall  f1-score   support\n",
            "\n",
            "Not-Predatorial       1.00      1.00      1.00    118092\n",
            "    Predatorial       0.81      0.45      0.58       252\n",
            "\n",
            "       accuracy                           1.00    118344\n",
            "      macro avg       0.90      0.73      0.79    118344\n",
            "   weighted avg       1.00      1.00      1.00    118344\n",
            "\n",
            "F0.5 - 0.6985\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import hashlib\n",
        "import hmac\n",
        "import random\n",
        "from math import floor\n",
        "import bitstring\n",
        "from sklearn.base import clone\n",
        "\n",
        "def verify_dawn(true_predictions, predictions, error_rate):\n",
        "    \"\"\"\n",
        "    Verify predictions on the non-trained on DAWN sample datapoints\n",
        "    \"\"\"\n",
        "    trigger_size = len(predictions)\n",
        "    mismatch = sum([int(y_pred != y_true) for y_true, y_pred in zip(true_predictions, predictions)])\n",
        "\n",
        "    accuracy = mismatch / trigger_size # Backdoor ratio - L(T,B^(T),F')\n",
        "    score = mismatch\n",
        "    stolen = accuracy >= error_rate\n",
        "\n",
        "    return accuracy, score, stolen\n",
        "\n",
        "class TFIDWatermarkedClassifier():\n",
        "    def __init__(self, classification_model, vectorization_model, r_w, precision_dawn, hmac_key_dawn, error_rate):\n",
        "        self.model = classification_model\n",
        "        self.tfidfvectorizer = vectorization_model\n",
        "        \n",
        "        # DAWN related settings\n",
        "        self.r_w = r_w\n",
        "        self.precision_dawn = precision_dawn \n",
        "        self.hmac_key_dawn = hmac_key_dawn\n",
        "        self.bound_dawn = 0 \n",
        "        self.model_watermarked = False\n",
        "        self.error_rate = error_rate\n",
        "    \n",
        "    def generate_trigger_set(self, train_x, train_y):\n",
        "        \"\"\"\n",
        "        Using Dynamic Adversarial Watermarking (DAWN)\n",
        "        \"\"\"\n",
        "        modified_x, modified_y = [], []\n",
        "        ownership = {}\n",
        "        for chat, label in zip(train_x, train_y):\n",
        "            if not self.should_predict_correctly(chat):\n",
        "                modified_x.append(chat)\n",
        "                modified_y.append(label)\n",
        "\n",
        "        # ownership information for the trigger\n",
        "        ownership['wm_inputs'] = modified_x\n",
        "        ownership['wm_labels'] = modified_y\n",
        "        ownership['bounds'] = (min(train_y), max(train_y))\n",
        "\n",
        "        return ownership, train_x, train_y\n",
        "    \n",
        "    def should_predict_correctly(self, chat):\n",
        "        \"\"\"\n",
        "        return if the model should classified this chat correctly or not according to DAWN\n",
        "        \"\"\"\n",
        "        hashed = hmac.new(self.hmac_key_dawn.encode(\"utf-8\"), chat.encode(\"utf-8\"), hashlib.sha256).hexdigest()\n",
        "        bits = bitstring.BitArray(hex=hashed).bin\n",
        "        \n",
        "        # If we only look at the first precision_dawn bits and only take the hashes where the first precision_dawn is zero\n",
        "        # than we take 1 / (2**precision_dawn) samples for the watermark ownership -> which is approx the r_w * TRAIN_SIZE\n",
        "        return False if int(bits[:self.precision_dawn], 2) <= self.bound_dawn else True\n",
        "    \n",
        "    def train_step(self, ownership, train_x, train_y):\n",
        "        X_train_tf  = self.tfidfvectorizer.fit_transform(train_x)\n",
        "        X_train_tf = self.tfidfvectorizer.transform(train_x)\n",
        "        self.model.fit(X_train_tf, train_y)\n",
        "\n",
        "        predictions = self.model.predict(self.tfidfvectorizer.transform(ownership['wm_inputs']))\n",
        "        accuracy, score, stolen = verify_dawn(ownership['wm_labels'], predictions, self.error_rate)\n",
        "\n",
        "        if stolen:\n",
        "            self.model_watermarked = True\n",
        "\n",
        "    def fit(self, train_x, train_y):\n",
        "        ownership, train_x, train_y = self.generate_trigger_set(train_x, train_y)\n",
        "        self.train_step(ownership, train_x, train_y)\n",
        "        return ownership\n",
        "\n",
        "    def predict(self, test_x):\n",
        "        X_test_tf = self.tfidfvectorizer.transform(test_x)\n",
        "        y_pred = self.model.predict(X_test_tf)\n",
        "        returned_predictions = []\n",
        "        for chat, pred in zip(test_x, y_pred):\n",
        "            if self.should_predict_correctly(chat):\n",
        "                returned_predictions.append(pred)\n",
        "            else:\n",
        "                returned_predictions.append(int(not pred)) # 1->0 and 0->1 miss classify on purpose\n",
        "        \n",
        "        return returned_predictions\n"
      ],
      "metadata": {
        "id": "ZRdukzm-GVSk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def test_dawn_watermark(train_x, train_y, test_x, test_y):\n",
        "    # Settings\n",
        "    ERROR_RATE = 0.001\n",
        "    PRECISION_DAWN = 8\n",
        "    r_w = 1 / (2 ** PRECISION_DAWN)\n",
        "    HMAC_DAWN_KEY = \"secret_key\"\n",
        "    train_x = concat_dataset(train_x)\n",
        "    test_x = concat_dataset(test_x)\n",
        "    classification_model = MultinomialNB()\n",
        "    vectorization_model = TfidfVectorizer(analyzer='word', stop_words='english')\n",
        "\n",
        "    print(\"Testing DAWN Watermark with settings:\")\n",
        "    print(f\"ERROR_RATE: {ERROR_RATE}\")\n",
        "    print(f\"r_w: {r_w}\")\n",
        "    print(f\"HMAC_DAWN_KEY: {HMAC_DAWN_KEY}\")\n",
        "    print(f\"Vectorize Model: TfidfVectorizer\")\n",
        "    print(f\"Classification Model: MultinomialNB\")\n",
        "    print()\n",
        "    \n",
        "    # main watermarked model\n",
        "    print(\"Creating watermarked model...\")\n",
        "    wm_model = TFIDWatermarkedClassifier(clone(classification_model), clone(vectorization_model), r_w=r_w, precision_dawn=PRECISION_DAWN, hmac_key_dawn=HMAC_DAWN_KEY, error_rate=ERROR_RATE)\n",
        "    ownership = wm_model.fit(train_x, train_y)\n",
        "\n",
        "    # Creating a non-watermarked model\n",
        "    print(\"Creating non-watermarked model...\")\n",
        "    non_wm_model = clone(classification_model)\n",
        "    non_wm_vectorization_model = clone(vectorization_model)\n",
        "    X_train_tf  = non_wm_vectorization_model.fit_transform(train_x)\n",
        "    X_train_tf = non_wm_vectorization_model.transform(train_x)\n",
        "    non_wm_model.fit(X_train_tf, train_y)\n",
        "\n",
        "    # Clean model not detected as stolen model\n",
        "    print(\"Testing not-stolen (non-watermarked) model...\")\n",
        "    no_wm_model_predictions = non_wm_model.predict(non_wm_vectorization_model.transform(ownership['wm_inputs']))\n",
        "    accuracy, score, stolen = verify_dawn(ownership['wm_labels'], no_wm_model_predictions, ERROR_RATE)\n",
        "    if stolen:\n",
        "        print(\"verify_dawn: Stolen Model!\")\n",
        "    else:\n",
        "        print(\"verify_dawn: Not Stolen Model!\")\n",
        "\n",
        "    print()\n",
        "    print(\"Testing stolen (watermarked) model...\")\n",
        "    wm_model_predictions = wm_model.predict(ownership['wm_inputs'])\n",
        "    accuracy, score, stolen = verify_dawn(ownership['wm_labels'], wm_model_predictions, ERROR_RATE)\n",
        "    if stolen:\n",
        "        print(\"verify_dawn: Stolen Model!\")\n",
        "    else:\n",
        "        print(\"verify_dawn: Not Stolen Model!\")\n",
        "    \n",
        "    print()\n",
        "    print(\"Testing how WM effected the model's performance\")\n",
        "    print(\"Test watermarked model...\")\n",
        "    wm_model_predictions = wm_model.predict(test_x)\n",
        "    print(metrics.classification_report(test_y, wm_model_predictions, target_names=['Not-Predatorial', 'Predatorial']))\n",
        "    print(f\"F0.5 - {metrics.fbeta_score(test_y, wm_model_predictions, beta=0.5):0.4f}\")\n",
        "\n",
        "\n",
        "    print()\n",
        "    print(\"Test non-watermarked model...\")\n",
        "    no_wm_model_predictions = non_wm_model.predict(non_wm_vectorization_model.transform(test_x))\n",
        "    print(metrics.classification_report(test_y, no_wm_model_predictions, target_names=['Not-Predatorial', 'Predatorial']))\n",
        "    print(f\"F0.5 - {metrics.fbeta_score(test_y, no_wm_model_predictions, beta=0.5):0.4f}\")\n"
      ],
      "metadata": {
        "id": "54_OdHLiVusI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"----------- This tests WM model accuracy on a *very unequal* sized dataset -----------\")\n",
        "pj_X_train, pj_X_test, pj_y_train, pj_y_test = train_test_split(pj_x, pj_y, test_size=0.33, random_state=42)\n",
        "complete_train_x = pan_train_x + pj_X_train\n",
        "complete_train_y = pan_train_y + pj_y_train\n",
        "under_train_x, under_train_y = undersample_class(complete_train_x, complete_train_y, oversampled_class=0, target_num_samples=700)\n",
        "test_dawn_watermark(under_train_x, under_train_y, pan_test_x + pj_X_test, pan_test_y + pj_y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aIXEeE8qJU3a",
        "outputId": "ba9161dd-94f3-4fa7-e297-da3aa5a058b8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------- This tests WM model accuracy on a *very unequal* sized dataset -----------\n",
            "Testing DAWN Watermark with settings:\n",
            "ERROR_RATE: 0.001\n",
            "r_w: 0.00390625\n",
            "HMAC_DAWN_KEY: secret_key\n",
            "Vectorize Model: TfidfVectorizer\n",
            "Classification Model: MultinomialNB\n",
            "\n",
            "Creating watermarked model...\n",
            "Creating non-watermarked model...\n",
            "Testing not-stolen (non-watermarked) model...\n",
            "verify_dawn: Not Stolen Model!\n",
            "\n",
            "Testing stolen (watermarked) model...\n",
            "verify_dawn: Stolen Model!\n",
            "\n",
            "Testing how WM effected the model's performance\n",
            "Test watermarked model...\n",
            "                 precision    recall  f1-score   support\n",
            "\n",
            "Not-Predatorial       1.00      1.00      1.00     38685\n",
            "    Predatorial       0.54      0.76      0.63       235\n",
            "\n",
            "       accuracy                           0.99     38920\n",
            "      macro avg       0.77      0.88      0.81     38920\n",
            "   weighted avg       1.00      0.99      1.00     38920\n",
            "\n",
            "F0.5 - 0.5726\n",
            "\n",
            "Test non-watermarked model...\n",
            "                 precision    recall  f1-score   support\n",
            "\n",
            "Not-Predatorial       1.00      1.00      1.00     38685\n",
            "    Predatorial       0.89      0.76      0.82       235\n",
            "\n",
            "       accuracy                           1.00     38920\n",
            "      macro avg       0.94      0.88      0.91     38920\n",
            "   weighted avg       1.00      1.00      1.00     38920\n",
            "\n",
            "F0.5 - 0.8614\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"----------- This tests WM model accuracy on an ~equal sized dataset -----------\")\n",
        "\n",
        "pj_X_train, pj_X_test, pj_y_train, pj_y_test = train_test_split(pj_x, pj_y, test_size=0.33, random_state=42)\n",
        "complete_train_x = pan_train_x + pj_X_train\n",
        "complete_train_y = pan_train_y + pj_y_train\n",
        "under_train_x, under_train_y = undersample_class(complete_train_x, complete_train_y, oversampled_class=0, target_num_samples=700)\n",
        "under_test_x, under_test_y = undersample_class(pan_test_x + pj_X_test, pan_test_y + pj_y_test, oversampled_class=0, target_num_samples=500)\n",
        "test_dawn_watermark(under_train_x, under_train_y, under_test_x, under_test_y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mwZecFq1hNEw",
        "outputId": "953d5a9f-0793-4671-b54c-89723ccb0d63"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------- This tests WM model accuracy on an ~equal sized dataset -----------\n",
            "Testing DAWN Watermark with settings:\n",
            "ERROR_RATE: 0.001\n",
            "r_w: 0.00390625\n",
            "HMAC_DAWN_KEY: secret_key\n",
            "Vectorize Model: TfidfVectorizer\n",
            "Classification Model: MultinomialNB\n",
            "\n",
            "Creating watermarked model...\n",
            "Creating non-watermarked model...\n",
            "Testing not-stolen (non-watermarked) model...\n",
            "verify_dawn: Not Stolen Model!\n",
            "\n",
            "Testing stolen (watermarked) model...\n",
            "verify_dawn: Stolen Model!\n",
            "\n",
            "Testing how WM effected the model's performance\n",
            "Test watermarked model...\n",
            "                 precision    recall  f1-score   support\n",
            "\n",
            "Not-Predatorial       0.90      1.00      0.94       500\n",
            "    Predatorial       0.99      0.76      0.86       235\n",
            "\n",
            "       accuracy                           0.92       735\n",
            "      macro avg       0.94      0.88      0.90       735\n",
            "   weighted avg       0.93      0.92      0.92       735\n",
            "\n",
            "F0.5 - 0.9333\n",
            "\n",
            "Test non-watermarked model...\n",
            "                 precision    recall  f1-score   support\n",
            "\n",
            "Not-Predatorial       0.90      1.00      0.95       500\n",
            "    Predatorial       1.00      0.76      0.86       235\n",
            "\n",
            "       accuracy                           0.92       735\n",
            "      macro avg       0.95      0.88      0.91       735\n",
            "   weighted avg       0.93      0.92      0.92       735\n",
            "\n",
            "F0.5 - 0.9411\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "Xjsjna-mIszN",
        "LiUEGi9Bq3s5",
        "ZL2iRDRmrZqU",
        "MEJKsj0-q78Q",
        "RG8ybBUY6VAl",
        "JzYYw1v4La5c",
        "XF282_rn0tmJ"
      ],
      "provenance": [],
      "machine_shape": "hm",
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}